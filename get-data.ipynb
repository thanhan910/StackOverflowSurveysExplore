{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:24<00:00,  1.77s/it]\n",
      "C:\\Users\\An\\AppData\\Local\\Temp\\ipykernel_4724\\1963751878.py:225: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataframes[2016]['schema']['Survey Question'].replace({'': np.nan}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urljoin\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "SESSION = requests.Session()\n",
    "SURVEYS_DATABASE_PAGE_URL = 'https://survey.stackoverflow.co/'\n",
    "DATA_FOLDER_PATH = 'local/data'\n",
    "\n",
    "\n",
    "def get_surveydata_links():\n",
    "    response = SESSION.get(SURVEYS_DATABASE_PAGE_URL)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    data_gps_tracks = soup.find_all('a', {'data-gps-track': True, 'data-year': True})\n",
    "    data_gps_tracks_links = [(urljoin(response.url, a['href']), a['data-year']) for a in data_gps_tracks]\n",
    "    return data_gps_tracks_links\n",
    "\n",
    "\n",
    "def download_surveydata_files(url: str, year):\n",
    "    \n",
    "    response = SESSION.get(url)\n",
    "    \n",
    "    # Extract the file type from the url\n",
    "    file_type = url.split('.')[-1]\n",
    "\n",
    "    # Assert that the file type is zip\n",
    "    assert file_type == 'zip', f'File type {file_type} is not supported'\n",
    "    \n",
    "    # Save the file\n",
    "    file_name = f'{year}.{file_type}'\n",
    "    with open(file_name, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    # Extract the zip file\n",
    "    path_to_extract = os.path.join(DATA_FOLDER_PATH, year)\n",
    "    with zipfile.ZipFile(f'{year}.{file_type}', 'r') as zip_ref:\n",
    "        zip_ref.extractall(path_to_extract)\n",
    "    \n",
    "    # Remove the zip file\n",
    "    os.remove(file_name)\n",
    "\n",
    "    # Remove __MACOSX folder if it exists\n",
    "    macosx_folder_path = os.path.join(path_to_extract, '__MACOSX')\n",
    "    if os.path.exists(macosx_folder_path) and os.path.isdir(macosx_folder_path):\n",
    "        shutil.rmtree(macosx_folder_path)\n",
    "\n",
    "\n",
    "def download_all_survey_data():\n",
    "    data_gps_tracks_links = get_surveydata_links()\n",
    "    for link, year in tqdm(data_gps_tracks_links):\n",
    "        download_surveydata_files(link, year)\n",
    "        # 5s per file\n",
    "        # Remove __MACOSX folder\n",
    "\n",
    "# download_all_survey_data()\n",
    "\n",
    "def get_csv_files():\n",
    "    csv_files : dict[int, list] = {}\n",
    "    data_folder_path_levels = len(DATA_FOLDER_PATH.split(os.sep))\n",
    "    for root, dirs, files in os.walk(DATA_FOLDER_PATH):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                folders = root.split(os.sep)\n",
    "                year = int(folders[data_folder_path_levels])\n",
    "                if year not in csv_files:\n",
    "                    csv_files[year] = []\n",
    "                # Skip __MACOSX\n",
    "                if '__MACOSX' in file_path:\n",
    "                    continue\n",
    "                csv_files[year].append(file_path)\n",
    "\n",
    "    for year in csv_files:\n",
    "        if year >= 2017:\n",
    "            assert len(csv_files[year]) == 2, f'Year {year} has {len(csv_files[year])} files'\n",
    "            # Assert that the 2 csv files are survey_results_schema.csv and survey_results_public.csv\n",
    "            for file in csv_files[year]:\n",
    "                assert file.endswith('survey_results_schema.csv') or file.endswith('survey_results_public.csv'), f'File {file} is not supported'\n",
    "        else:\n",
    "            assert len(csv_files[year]) == 1, f'Year {year} has {len(csv_files[year])} files'\n",
    "\n",
    "    return csv_files\n",
    "\n",
    "csv_files = get_csv_files()\n",
    "\n",
    "def get_2016_schema_table():\n",
    "\n",
    "    def get_readme_2016_filepath():\n",
    "        for root, dirs, files in os.walk(os.path.join(DATA_FOLDER_PATH, '2016')):\n",
    "            if '__MACOSX' in root:\n",
    "                continue\n",
    "            for file in files:\n",
    "                if file.endswith('.txt'):\n",
    "                    readme_file_path = os.path.join(root, file)\n",
    "                    return readme_file_path\n",
    "\n",
    "    readme_file_path : str = get_readme_2016_filepath()\n",
    "\n",
    "\n",
    "    with open(readme_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    # Get all lines from \"Database schema:\" to the end\n",
    "    for i, line in enumerate(lines):\n",
    "        if 'Database schema:' in line:\n",
    "            schema_table_lines = [line for line in lines[i+1:] if line.strip() != '']\n",
    "            break\n",
    "\n",
    "    schema_table_header = schema_table_lines[0].split(' --- ')\n",
    "    schema_table_header = [cell.strip().strip(\"'\").strip('\"') for cell in schema_table_header]\n",
    "    schema_table_rows = [line.split(' --- ') for line in schema_table_lines[1:]]\n",
    "    schema_table_rows = [[cell.strip().strip(\"'\").strip('\"') for cell in row] for row in schema_table_rows]\n",
    "    schema_table_rows = [['' if cell == 'N/A' else cell for cell in row] for row in schema_table_rows]\n",
    "\n",
    "    schema_table_rows = [['Respondent', '', ''],] + schema_table_rows\n",
    "\n",
    "    schema_table_df = pd.DataFrame(schema_table_rows, columns=schema_table_header)\n",
    "\n",
    "    return schema_table_df\n",
    "\n",
    "def get_dataframes(csv_files):\n",
    "\n",
    "    dataframes = {}\n",
    "\n",
    "    for year, files in tqdm(csv_files.items()):\n",
    "        dataframes[year] = {}\n",
    "        \n",
    "        if year <= 2015:\n",
    "            # If year <= 2015, the csv file has two top rows as headers\n",
    "            assert len(files) == 1\n",
    "            file_path = files[0]\n",
    "            \n",
    "            try:\n",
    "                df_schema = pd.read_csv(file_path, nrows=2, header=None)\n",
    "            except UnicodeDecodeError:\n",
    "                df_schema = pd.read_csv(file_path, nrows=2, encoding='latin1', header=None)\n",
    "            try:\n",
    "                df_content = pd.read_csv(file_path, skiprows=2, header=None, low_memory=False)\n",
    "            except UnicodeDecodeError:\n",
    "                df_content = pd.read_csv(file_path, skiprows=2, encoding='latin1', header=None, low_memory=False)\n",
    "\n",
    "            df_schema = df_schema.transpose().reset_index(drop=False)\n",
    "\n",
    "            if year < 2015:\n",
    "                df_schema.rename(columns={0: 'Question', 1: 'Answer', 'index': 'Column'}, inplace=True)\n",
    "            else: # year == 2015\n",
    "                df_schema.rename(columns={0: 'Question Type', 1: 'Question', 'index': 'Column'}, inplace=True)\n",
    "            \n",
    "            dataframes[year] = {\n",
    "                'schema': df_schema,\n",
    "                'content': df_content,\n",
    "            }\n",
    "\n",
    "        elif year == 2016:\n",
    "            file_path = files[0]\n",
    "            df_schema = get_2016_schema_table()\n",
    "            df_content = pd.read_csv(file_path, low_memory=False)\n",
    "            assert df_content['Unnamed: 0'].is_unique\n",
    "            assert 'Respondent' not in df_content.columns\n",
    "            df_content.rename(columns={'Unnamed: 0': 'Respondent'}, inplace=True)\n",
    "            dataframes[year] = {\n",
    "                'schema': df_schema,\n",
    "                'content': df_content,\n",
    "            }\n",
    "        else:\n",
    "            for file_path in files:\n",
    "                if 'survey_results_public' in file_path:\n",
    "                    content_file_path = file_path\n",
    "                else:\n",
    "                    assert 'survey_results_schema' in file_path\n",
    "                    schema_file_path = file_path\n",
    "            \n",
    "            df_schema = pd.read_csv(schema_file_path)\n",
    "            df_content = pd.read_csv(content_file_path, low_memory=False)\n",
    "            dataframes[year] = {\n",
    "                'schema': df_schema,\n",
    "                'content': df_content,\n",
    "            }\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "# 2011 - 2014\n",
    "# 2015\n",
    "# 2016\n",
    "# 2017 - 2020\n",
    "# 2021 - 2024\n",
    "\n",
    "dataframes : dict[int, dict[str, pd.DataFrame]] = get_dataframes(csv_files)\n",
    "\n",
    "# Transform 2011 - 2014 dataframes\n",
    "for year in range(2011, 2015):\n",
    "    schema_rows = dataframes[year]['schema'].to_dict(orient='records')\n",
    "    it = 0\n",
    "    for r in schema_rows:\n",
    "        if(not pd.isna(r['Question'])):\n",
    "            it += 1\n",
    "        r['QID'] = f'Q{it}'\n",
    "    dataframes[year]['schema'] = pd.DataFrame(schema_rows, columns=['QID', 'Column', 'Question', 'Answer'])\n",
    "    dataframes[year]['questions'] = dataframes[year]['schema'][['QID', 'Question']].drop_duplicates(subset=['Question'], keep='first', inplace=False)\n",
    "    dataframes[year]['schema'].drop(columns=['Question'], inplace=True)\n",
    "    dataframes[year]['content'].columns = [f'C{col + 1}' for col in dataframes[year]['content'].columns]\n",
    "    dataframes[year]['schema']['Column'] = dataframes[2015]['schema']['Column'].apply(lambda x: f'C{x + 1}')\n",
    "\n",
    "# Transform 2015 dataframes\n",
    "dataframes[2015]['schema']['Answer'] = dataframes[2015]['schema']['Question'].str.split(': ').apply(lambda x: x[1] if len(x) > 1 else np.nan)\n",
    "dataframes[2015]['schema']['Question'] = dataframes[2015]['schema']['Question'].str.split(': ').apply(lambda x: x[0])\n",
    "dataframes[2015]['questions'] = dataframes[2015]['schema'].drop_duplicates(subset=['Question'], keep='first', inplace=False)[['Question', 'Question Type']]\n",
    "dataframes[2015]['questions'].reset_index(drop=True, inplace=True)\n",
    "dataframes[2015]['questions'].reset_index(drop=False, inplace=True)\n",
    "dataframes[2015]['questions'].rename(columns={'index': 'QID'}, inplace=True)\n",
    "dataframes[2015]['questions']['QID'] = dataframes[2015]['questions']['QID'].apply(lambda x: f'Q{x+1}')\n",
    "dataframes[2015]['schema'].reset_index(drop=False, inplace=True)\n",
    "dataframes[2015]['schema'].drop(columns=['Question Type'], inplace=True)\n",
    "dataframes[2015]['schema'] = pd.merge(dataframes[2015]['schema'], dataframes[2015]['questions'], on='Question', how='left', suffixes=('', '_y'))[['QID', 'Column', 'Answer']]\n",
    "\n",
    "dataframes[2015]['content'].columns = [f'C{col + 1}' for col in dataframes[2015]['content'].columns]\n",
    "dataframes[2015]['schema']['Column'] = dataframes[2015]['schema']['Column'].apply(lambda x: f'C{x + 1}')\n",
    "\n",
    "\n",
    "# Transform 2016 dataframes\n",
    "dataframes[2016]['schema']['Survey Question'] = dataframes[2016]['schema']['Survey Question'].replace('', np.nan, inplace=True)\n",
    "dataframes[2016]['questions'] = dataframes[2016]['schema']['Survey Question'].drop_duplicates(keep='first', inplace=False).dropna().reset_index(drop=True, inplace=False).reset_index(drop=False, inplace=False).rename(columns={'index': 'QID'}, inplace=False)\n",
    "dataframes[2016]['questions']['QID'] = dataframes[2016]['questions']['QID'].apply(lambda x: f'Q{x+1}')\n",
    "dataframes[2016]['schema'] = dataframes[2016]['schema'].merge(dataframes[2016]['questions'], left_on='Survey Question', right_on='Survey Question', how='left', suffixes=('', '_y'))[['QID', 'Column Name', 'Note (if any)']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>qname</th>\n",
       "      <th>question</th>\n",
       "      <th>force_resp</th>\n",
       "      <th>type</th>\n",
       "      <th>selector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QID2</td>\n",
       "      <td>MainBranch</td>\n",
       "      <td>Which of the following options best describes ...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>MC</td>\n",
       "      <td>SAVR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QID127</td>\n",
       "      <td>Age</td>\n",
       "      <td>What is your age?*</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>MC</td>\n",
       "      <td>SAVR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QID296</td>\n",
       "      <td>Employment</td>\n",
       "      <td>Which of the following best describes your cur...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>MC</td>\n",
       "      <td>MAVR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QID308</td>\n",
       "      <td>RemoteWork</td>\n",
       "      <td>Which best describes your current work situation?</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>MC</td>\n",
       "      <td>SAVR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QID341</td>\n",
       "      <td>Check</td>\n",
       "      <td>Just checking to make sure you are paying atte...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>MC</td>\n",
       "      <td>SAVR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>QID337</td>\n",
       "      <td>JobSatPoints_7</td>\n",
       "      <td>Learning and using new technology, including p...</td>\n",
       "      <td>NA</td>\n",
       "      <td>MC</td>\n",
       "      <td>MAVR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>QID337</td>\n",
       "      <td>JobSatPoints_8</td>\n",
       "      <td>Designing and building environments, databases...</td>\n",
       "      <td>NA</td>\n",
       "      <td>MC</td>\n",
       "      <td>MAVR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>QID337</td>\n",
       "      <td>JobSatPoints_9</td>\n",
       "      <td>Being a power user of a tool, developer langua...</td>\n",
       "      <td>NA</td>\n",
       "      <td>MC</td>\n",
       "      <td>MAVR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>QID337</td>\n",
       "      <td>JobSatPoints_10</td>\n",
       "      <td>Working with new and/or top-quality hardware</td>\n",
       "      <td>NA</td>\n",
       "      <td>MC</td>\n",
       "      <td>MAVR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>QID337</td>\n",
       "      <td>JobSatPoints_11</td>\n",
       "      <td>A well-staffed/sourced internal network that m...</td>\n",
       "      <td>NA</td>\n",
       "      <td>MC</td>\n",
       "      <td>MAVR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid            qname  \\\n",
       "0     QID2       MainBranch   \n",
       "1   QID127              Age   \n",
       "2   QID296       Employment   \n",
       "3   QID308       RemoteWork   \n",
       "4   QID341            Check   \n",
       "..     ...              ...   \n",
       "82  QID337   JobSatPoints_7   \n",
       "83  QID337   JobSatPoints_8   \n",
       "84  QID337   JobSatPoints_9   \n",
       "85  QID337  JobSatPoints_10   \n",
       "86  QID337  JobSatPoints_11   \n",
       "\n",
       "                                             question force_resp type selector  \n",
       "0   Which of the following options best describes ...       TRUE   MC     SAVR  \n",
       "1                                  What is your age?*       TRUE   MC     SAVR  \n",
       "2   Which of the following best describes your cur...       TRUE   MC     MAVR  \n",
       "3   Which best describes your current work situation?      FALSE   MC     SAVR  \n",
       "4   Just checking to make sure you are paying atte...       TRUE   MC     SAVR  \n",
       "..                                                ...        ...  ...      ...  \n",
       "82  Learning and using new technology, including p...         NA   MC     MAVR  \n",
       "83  Designing and building environments, databases...         NA   MC     MAVR  \n",
       "84  Being a power user of a tool, developer langua...         NA   MC     MAVR  \n",
       "85       Working with new and/or top-quality hardware         NA   MC     MAVR  \n",
       "86  A well-staffed/sourced internal network that m...         NA   MC     MAVR  \n",
       "\n",
       "[87 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframes[2024]['content']['EdLevel'].unique()\n",
    "dataframes[2024]['schema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes[2016]['schema'][dataframes[2016]['schema']['Survey Question'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes[2015]['schema']['Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_unmatched_qnames(year, df_schema, df_content):\n",
    "    assert year >= 2021\n",
    "    unmatched_qnames = sorted(set(df_schema['qname']) - set(df_content.columns))\n",
    "    unmatched_columns = sorted(set(df_content.columns) - set(df_schema['qname']))\n",
    "    i = 0\n",
    "    j = 0\n",
    "    min_j_assessed = 0\n",
    "    i_isfound = False\n",
    "    columns_qname = {col:  None for col in unmatched_columns}\n",
    "    qname_columns = {qname: [] for qname in unmatched_qnames}\n",
    "    columns_qname_found = []\n",
    "    while (i < len(unmatched_qnames)) and (min_j_assessed < len(unmatched_columns)):\n",
    "        if unmatched_columns[j].startswith(unmatched_qnames[i]):\n",
    "            i_isfound = True\n",
    "            qname_columns[unmatched_qnames[i]].append(unmatched_columns[j])\n",
    "            columns_qname[unmatched_columns[j]] = unmatched_qnames[i]\n",
    "            j += 1\n",
    "            min_j_assessed = j\n",
    "        else:\n",
    "            if i_isfound:\n",
    "                i += 1\n",
    "                i_isfound = False\n",
    "            else:\n",
    "                j += 1\n",
    "            if not i_isfound and j == len(unmatched_columns):\n",
    "                j = min_j_assessed\n",
    "                i += 1\n",
    "    return qname_columns, columns_qname\n",
    "\n",
    "for year in range(2021, 2025):\n",
    "    qname_columns, columns_qname = match_unmatched_qnames(year, dataframes[year]['schema'], dataframes[year]['content'])\n",
    "    # assert columns_qname_notfound == ['ConvertedCompYearly', 'ResponseId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes[2015]['schema'][dataframes[2015]['schema']['Answer'].notna()]\n",
    "# dataframes[2015]['schema'].to_csv('2015_schema.csv')\n",
    "# dataframes[2016]['schema'].to_csv('2016_schema.csv')\n",
    "dataframes[2015]['schema']['Question'].str.split(': ').apply(lambda x: len(x))\n",
    "rows_2015 = dataframes[2015]['schema'].to_dict(orient='records')\n",
    "rows_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021\n",
    "qname_columns, columns_qname = match_unmatched_qnames(year, dataframes[year]['schema'], dataframes[year]['content'])\n",
    "unmatched_columns = [col for col in columns_qname if columns_qname[col] is None]\n",
    "unmatched_qnames = [qname for qname in qname_columns if qname_columns[qname] == []]\n",
    "assert unmatched_columns == ['ConvertedCompYearly', 'ResponseId']\n",
    "dataframes[year]['schema'][dataframes[year]['schema']['qname'].apply(lambda x: any(x.startswith(qname) for qname in unmatched_qnames))].sort_values(by='qname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes[year]['content'][dataframes[year]['content']['Frequency_1'].notna()]['Frequency_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in columns_qname if columns_qname[col] is None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dataframes[2021]['content'].columns) - set(dataframes[2021]['schema']['qname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dataframes[2021]['schema']['qname']) - set(dataframes[2021]['content'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes[2020]['schema']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dataframes[2024]['schema']['qname'].unique()) - set(dataframes[2024]['content'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes[2024]['schema']['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dataframes[2024]['content'].columns) - set(dataframes[2024]['schema']['qname'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
